{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from scipy.signal import decimate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPool1D, GlobalAvgPool1D, Dropout, BatchNormalization, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'murmur': 1}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "INPUT_LIB = ''\n",
    "SAMPLE_RATE = 4000\n",
    "CLASSES = ['normal', 'murmur']\n",
    "CODE_BOOK = {x:i for i,x in enumerate(CLASSES)}\n",
    "print(CODE_BOOK)\n",
    "NB_CLASSES = len(CLASSES)\n",
    "print(NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_filename(fname, string):   \n",
    "    file_name = fname.split('_',3)[2]\n",
    "    fn=fname.split('_',3)[3]\n",
    "    return file_name+'__'+fn\n",
    "def load_wav_file(name, path):\n",
    "    _, b = wavfile.read(path + name)\n",
    "#     print(_)\n",
    "    assert _ == SAMPLE_RATE\n",
    "    return b\n",
    "def repeat_to_length(arr, length):\n",
    "    \"\"\"Repeats the numpy 1D array to given length, and makes datatype float\"\"\"\n",
    "    result = np.empty((length, ), dtype = 'float32')\n",
    "    l = len(arr)\n",
    "    pos = 0\n",
    "    while pos + l <= length:\n",
    "        result[pos:pos+l] = arr\n",
    "        pos += l\n",
    "    if pos < length:\n",
    "        result[pos:length] = arr[:length-pos]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96640\n",
      "OK\n",
      "    dataset                             fname   label  sublabel  \\\n",
      "0         b   murmur__112_1306243000964_A.wav  murmur       NaN   \n",
      "1         b   murmur__112_1306243000964_B.wav  murmur       NaN   \n",
      "2         b   murmur__112_1306243000964_D.wav  murmur       NaN   \n",
      "3         b   murmur__116_1306258689913_A.wav  murmur       NaN   \n",
      "4         b   murmur__116_1306258689913_C.wav  murmur       NaN   \n",
      "5         b   murmur__116_1306258689913_D.wav  murmur       NaN   \n",
      "6         b   murmur__122_1306325762831_C.wav  murmur       NaN   \n",
      "7         b   murmur__122_1306325762831_D.wav  murmur       NaN   \n",
      "8         b   murmur__156_1306936373241_B.wav  murmur       NaN   \n",
      "9         b   murmur__160_1307100683334_A.wav  murmur       NaN   \n",
      "10        b   murmur__160_1307100683334_B.wav  murmur       NaN   \n",
      "11        b   murmur__161_1307101199321_A.wav  murmur       NaN   \n",
      "12        b   murmur__162_1307101835989_A.wav  murmur       NaN   \n",
      "13        b   murmur__162_1307101835989_B.wav  murmur       NaN   \n",
      "14        b   murmur__164_1307106095995_B.wav  murmur       NaN   \n",
      "15        b   murmur__164_1307106095995_C.wav  murmur       NaN   \n",
      "16        b   murmur__165_1307109069581_C.wav  murmur       NaN   \n",
      "17        b  murmur__165_1307109069581_C2.wav  murmur       NaN   \n",
      "18        b   murmur__171_1307971016233_D.wav  murmur       NaN   \n",
      "19        b  murmur__171_1307971016233_D1.wav  murmur       NaN   \n",
      "20        b   murmur__171_1307971016233_E.wav  murmur       NaN   \n",
      "21        b   murmur__185_1308073325396_B.wav  murmur       NaN   \n",
      "22        b   murmur__185_1308073325396_C.wav  murmur       NaN   \n",
      "23        b   murmur__193_1308078104592_B.wav  murmur       NaN   \n",
      "24        b   murmur__193_1308078104592_C.wav  murmur       NaN   \n",
      "25        b  murmur__193_1308078104592_C1.wav  murmur       NaN   \n",
      "26        b   murmur__195_1308140095331_A.wav  murmur       NaN   \n",
      "27        b   murmur__195_1308140095331_C.wav  murmur       NaN   \n",
      "28        b  murmur__195_1308140095331_C1.wav  murmur       NaN   \n",
      "29        b   murmur__196_1308141034858_B.wav  murmur       NaN   \n",
      "..      ...                               ...     ...       ...   \n",
      "102       b   normal__140_1306519735121_A.wav  normal       NaN   \n",
      "103       b   normal__140_1306519735121_B.wav  normal       NaN   \n",
      "104       b  normal__140_1306519735121_D1.wav  normal       NaN   \n",
      "105       b   normal__141_1306520154450_B.wav  normal       NaN   \n",
      "106       b   normal__141_1306520154450_C.wav  normal       NaN   \n",
      "107       b   normal__143_1306763822290_B.wav  normal       NaN   \n",
      "108       b   normal__143_1306763822290_C.wav  normal       NaN   \n",
      "109       b   normal__145_1307987561278_B.wav  normal       NaN   \n",
      "110       b   normal__145_1307987561278_C.wav  normal       NaN   \n",
      "111       b   normal__146_1306778707532_A.wav  normal       NaN   \n",
      "112       b   normal__146_1306778707532_B.wav  normal       NaN   \n",
      "113       b  normal__146_1306778707532_D1.wav  normal       NaN   \n",
      "114       b  normal__146_1306778707532_D2.wav  normal       NaN   \n",
      "115       b  normal__146_1306778707532_D3.wav  normal       NaN   \n",
      "116       b  normal__146_1306778707532_D4.wav  normal       NaN   \n",
      "117       b   normal__147_1306523973811_A.wav  normal       NaN   \n",
      "118       b   normal__147_1306523973811_C.wav  normal       NaN   \n",
      "119       b  normal__148_1306768801551_C1.wav  normal       NaN   \n",
      "120       b  normal__148_1306768801551_D2.wav  normal       NaN   \n",
      "121       b   normal__149_1306776016110_B.wav  normal       NaN   \n",
      "122       b  normal__149_1306776016110_C1.wav  normal       NaN   \n",
      "123       b   normal__150_1306776340746_B.wav  normal       NaN   \n",
      "124       b   normal__150_1306776340746_C.wav  normal       NaN   \n",
      "125       b   normal__151_1306779785624_A.wav  normal       NaN   \n",
      "126       b   normal__151_1306779785624_D.wav  normal       NaN   \n",
      "127       b  normal__152_1306779561195_B1.wav  normal       NaN   \n",
      "128       b  normal__152_1306779561195_C1.wav  normal       NaN   \n",
      "129       b   normal__152_1306779561195_D.wav  normal       NaN   \n",
      "130       b   normal__153_1306848820671_A.wav  normal       NaN   \n",
      "131       b   normal__153_1306848820671_B.wav  normal       NaN   \n",
      "\n",
      "                                           time_series  len_series  \n",
      "0    [934.0, 782.0, 697.0, 582.0, 659.0, 815.0, 883...       96640  \n",
      "1    [817.0, 879.0, 770.0, 529.0, 360.0, 262.0, 178...       96640  \n",
      "2    [1733.0, 2192.0, 2593.0, 2598.0, 2300.0, 1979....       96640  \n",
      "3    [-982.0, -973.0, -832.0, -813.0, -409.0, -231....       96640  \n",
      "4    [-18.0, 78.0, 42.0, 142.0, 234.0, -71.0, -47.0...       96640  \n",
      "5    [407.0, 303.0, 330.0, 374.0, 628.0, 490.0, 519...       96640  \n",
      "6    [-169.0, -137.0, -61.0, -101.0, -104.0, -84.0,...       96640  \n",
      "7    [-4489.0, -3741.0, -2782.0, -1958.0, -1117.0, ...       96640  \n",
      "8    [1009.0, 1037.0, 1293.0, 1475.0, 1462.0, 1358....       96640  \n",
      "9    [-3344.0, -3760.0, -4558.0, -4838.0, -6230.0, ...       96640  \n",
      "10   [1031.0, 1382.0, 1671.0, 2122.0, 2471.0, 2490....       96640  \n",
      "11   [210.0, -54.0, -172.0, -14.0, -172.0, -254.0, ...       96640  \n",
      "12   [615.0, -543.0, -1145.0, -1394.0, -702.0, -176...       96640  \n",
      "13   [-3157.0, -3055.0, -3158.0, -2669.0, -2073.0, ...       96640  \n",
      "14   [-4868.0, -3575.0, -2666.0, -2053.0, -2401.0, ...       96640  \n",
      "15   [761.0, 359.0, 433.0, 360.0, 428.0, 560.0, 578...       96640  \n",
      "16   [-90.0, -56.0, -26.0, -58.0, -32.0, -85.0, 45....       96640  \n",
      "17   [-221.0, 13.0, -64.0, 18.0, -87.0, -81.0, 94.0...       96640  \n",
      "18   [-291.0, 35.0, 511.0, 950.0, 1024.0, -69.0, -9...       96640  \n",
      "19   [5420.0, 5457.0, 5151.0, 4639.0, 4169.0, 3586....       96640  \n",
      "20   [-628.0, -824.0, -1022.0, -893.0, -852.0, -845...       96640  \n",
      "21   [-624.0, -1076.0, -1112.0, -599.0, -421.0, -51...       96640  \n",
      "22   [529.0, 994.0, 1475.0, 1526.0, 1194.0, 1304.0,...       96640  \n",
      "23   [291.0, 1135.0, -279.0, -846.0, 727.0, 1519.0,...       96640  \n",
      "24   [-295.0, -364.0, -217.0, 196.0, 356.0, 177.0, ...       96640  \n",
      "25   [11209.0, 11097.0, 10862.0, 10584.0, 10585.0, ...       96640  \n",
      "26   [557.0, 837.0, 860.0, 456.0, 84.0, -26.0, -159...       96640  \n",
      "27   [-737.0, -613.0, -716.0, -595.0, -460.0, -587....       96640  \n",
      "28   [-235.0, -315.0, -229.0, -265.0, -553.0, -395....       96640  \n",
      "29   [349.0, 554.0, 510.0, 702.0, 615.0, -134.0, 11...       96640  \n",
      "..                                                 ...         ...  \n",
      "102  [187.0, 251.0, 373.0, 491.0, 439.0, 410.0, 276...       96640  \n",
      "103  [-715.0, -594.0, -732.0, -744.0, -708.0, -846....       96640  \n",
      "104  [202.0, 315.0, 388.0, 449.0, 350.0, 279.0, 391...       96640  \n",
      "105  [-791.0, -888.0, -671.0, -214.0, 155.0, 398.0,...       96640  \n",
      "106  [-170.0, -12.0, 216.0, 392.0, 631.0, 727.0, 61...       96640  \n",
      "107  [-124.0, -251.0, -302.0, -104.0, -25.0, 92.0, ...       96640  \n",
      "108  [1015.0, 1112.0, 1163.0, 1183.0, 1321.0, 1298....       96640  \n",
      "109  [-446.0, -267.0, -360.0, -429.0, -299.0, -399....       96640  \n",
      "110  [-653.0, -514.0, -708.0, -568.0, -539.0, -768....       96640  \n",
      "111  [124.0, -153.0, -334.0, -538.0, -630.0, -610.0...       96640  \n",
      "112  [-9362.0, -9724.0, -8981.0, -7257.0, -5918.0, ...       96640  \n",
      "113  [825.0, 714.0, 588.0, 573.0, 510.0, 419.0, 356...       96640  \n",
      "114  [321.0, 536.0, 381.0, 341.0, 225.0, 221.0, 368...       96640  \n",
      "115  [-697.0, -593.0, -567.0, -689.0, -558.0, -587....       96640  \n",
      "116  [-608.0, -668.0, -702.0, -728.0, -694.0, -697....       96640  \n",
      "117  [1170.0, 1076.0, 1077.0, 997.0, 946.0, 929.0, ...       96640  \n",
      "118  [-285.0, -326.0, -258.0, -144.0, -203.0, -171....       96640  \n",
      "119  [-243.0, -460.0, -349.0, -354.0, -596.0, -434....       96640  \n",
      "120  [891.0, 757.0, 809.0, 759.0, 672.0, 603.0, 513...       96640  \n",
      "121  [-541.0, -287.0, -364.0, -345.0, -134.0, -257....       96640  \n",
      "122  [-133.0, 3.0, -48.0, 101.0, -16.0, -149.0, 22....       96640  \n",
      "123  [-109.0, 24.0, -84.0, -278.0, -427.0, -426.0, ...       96640  \n",
      "124  [-994.0, -1130.0, -1316.0, -1359.0, -1251.0, -...       96640  \n",
      "125  [-562.0, -476.0, -615.0, -718.0, -185.0, 75.0,...       96640  \n",
      "126  [822.0, 914.0, 952.0, 882.0, 944.0, 1256.0, 12...       96640  \n",
      "127  [-258.0, -243.0, -188.0, -34.0, 63.0, 102.0, -...       96640  \n",
      "128  [-231.0, -193.0, -96.0, -260.0, -244.0, -193.0...       96640  \n",
      "129  [1092.0, 622.0, 571.0, 776.0, 801.0, 413.0, -1...       96640  \n",
      "130  [-486.0, -147.0, -153.0, -375.0, -331.0, -184....       96640  \n",
      "131  [683.0, 823.0, 780.0, 629.0, 620.0, 608.0, 646...       96640  \n",
      "\n",
      "[132 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_LIB + 'set_b_new.csv')\n",
    "\n",
    "df['fname'] = df['fname'].apply(clean_filename, string='Bunlabelledtest')\n",
    "\n",
    "# df['label'] = df['label'].fillna('unclassified')\n",
    "\n",
    "# #print(df[150:])\n",
    "\n",
    "df['time_series'] = df['fname'].apply(load_wav_file, path=INPUT_LIB + 'set_b/')    \n",
    "df['len_series'] = df['time_series'].apply(len)\n",
    "MAX_LEN = max(df['len_series'])\n",
    "print(MAX_LEN)\n",
    "df['time_series'] = df['time_series'].apply(repeat_to_length, length=MAX_LEN) \n",
    "df['len_series'] = df['time_series'].apply(len)\n",
    "\n",
    "print(\"OK\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  934.   782.   697. ...,  -377.  -402.  -289.]\n",
      " [  817.   879.   770. ...,  3785.  3701.  3205.]\n",
      " [ 1733.  2192.  2593. ...,    59.    52.    67.]\n",
      " ..., \n",
      " [ 1092.   622.   571. ...,   368.    82.  -336.]\n",
      " [ -486.  -147.  -153. ...,   309.   251.   171.]\n",
      " [  683.   823.   780. ...,   185.    69.  -118.]]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.stack(df['time_series'].values, axis=0)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "new_labels =[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,]\n",
    "print(len(new_labels))\n",
    "new_labels = np.array(new_labels, dtype='int')\n",
    "y_data = np_utils.to_categorical(new_labels)\n",
    "print (y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, train_filenames, test_filenames = train_test_split(x_data, y_data, df['fname'].values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, train_filenames, test_filenames = train_test_split(x_data, y_data, df['fname'].values, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "[[ -1.52261236e+02   6.97962294e+01   1.74102681e+01 ...,  -2.25184404e+01\n",
      "   -4.09072940e+01   1.80502524e+02]\n",
      " [ -5.60964941e+01  -2.96922252e+01  -3.03894462e+01 ...,  -1.93122640e+01\n",
      "    1.33183353e+02  -2.50412673e+02]\n",
      " [  6.73191903e+00  -2.30098934e+01   8.71595496e+01 ...,   1.49426598e+02\n",
      "   -9.04920641e+01   1.05783393e+02]\n",
      " ..., \n",
      " [  1.72083871e+03  -3.77959175e+02   1.63148895e+02 ...,   5.26741897e+01\n",
      "   -6.10588105e-02   1.34744548e+02]\n",
      " [ -8.16803072e+02   3.07251451e+02  -1.37400668e+01 ...,  -9.79700123e+01\n",
      "    1.10649212e+02  -1.53449640e+01]\n",
      " [  2.16258720e+02  -7.15465158e+01   1.02921984e+02 ...,  -9.94204416e+00\n",
      "    1.22899368e+02  -1.62661723e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "x_train = decimate(x_train, 8, axis=1, zero_phase=True)\n",
    "x_train = decimate(x_train, 8, axis=1, zero_phase=True)\n",
    "x_train = decimate(x_train, 4, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 8, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 8, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 4, axis=1, zero_phase=True)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 378)\n"
     ]
    }
   ],
   "source": [
    "#Scale each observation to unit variance, it should already have mean close to zero.\n",
    "x_train = x_train / np.std(x_train, axis=1).reshape(-1,1)\n",
    "x_test = x_test / np.std(x_test, axis=1).reshape(-1,1)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 378, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:,:,np.newaxis]\n",
    "x_test = x_test[:,:,np.newaxis]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohit/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=4, kernel_size=9, activation='relu',\n",
    "                input_shape = x_train.shape[1:],\n",
    "                kernel_regularizer = l2(0.025)))\n",
    "model.add(MaxPool1D(strides=4))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Conv1D(filters=4, kernel_size=9, activation='relu',\n",
    "#                 kernel_regularizer = l2(0.05)))\n",
    "# model.add(MaxPool1D(strides=4))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=8, kernel_size=9, activation='relu',\n",
    "                 kernel_regularizer = l2(0.1)))\n",
    "model.add(MaxPool1D(strides=4))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Conv1D(filters=16, kernel_size=9, activation='relu'))\n",
    "# model.add(MaxPool1D(strides=4))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(GlobalAvgPool1D())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(x_train, y_train, batch_size):\n",
    "    \"\"\"\n",
    "    Rotates the time series randomly in time\n",
    "    \"\"\"\n",
    "    x_batch = np.empty((batch_size, x_train.shape[1], x_train.shape[2]), dtype='float32')\n",
    "    y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32')\n",
    "    full_idx = range(x_train.shape[0])\n",
    "    \n",
    "    while True:\n",
    "        batch_idx = np.random.choice(full_idx, batch_size)\n",
    "        x_batch = x_train[batch_idx]\n",
    "        y_batch = y_train[batch_idx]\n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            sz = np.random.randint(x_batch.shape[1])\n",
    "            x_batch[i] = np.roll(x_batch[i], sz, axis = 0)\n",
    "     \n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -4.86151067e+00]\n",
      "  [  2.22850624e+00]\n",
      "  [  5.55888069e-01]\n",
      "  ..., \n",
      "  [ -7.18985616e-01]\n",
      "  [ -1.30611870e+00]\n",
      "  [  5.76321966e+00]]\n",
      "\n",
      " [[ -1.27941191e+00]\n",
      "  [ -6.77200728e-01]\n",
      "  [ -6.93102486e-01]\n",
      "  ..., \n",
      "  [ -4.40461406e-01]\n",
      "  [  3.03755824e+00]\n",
      "  [ -5.71124742e+00]]\n",
      "\n",
      " [[  1.07640754e-01]\n",
      "  [ -3.67919201e-01]\n",
      "  [  1.39364713e+00]\n",
      "  ..., \n",
      "  [  2.38927289e+00]\n",
      "  [ -1.44693273e+00]\n",
      "  [  1.69143511e+00]]\n",
      "\n",
      " ..., \n",
      " [[  1.68535971e+01]\n",
      "  [ -3.70166688e+00]\n",
      "  [  1.59785210e+00]\n",
      "  ..., \n",
      "  [  5.15881916e-01]\n",
      "  [ -5.97999444e-04]\n",
      "  [  1.31966483e+00]]\n",
      "\n",
      " [[ -5.67425422e+00]\n",
      "  [  2.13444697e+00]\n",
      "  [ -9.54509533e-02]\n",
      "  ..., \n",
      "  [ -6.80588473e-01]\n",
      "  [  7.68669681e-01]\n",
      "  [ -1.06600023e-01]]\n",
      "\n",
      " [[  2.09873883e+00]\n",
      "  [ -6.94341719e-01]\n",
      "  [  9.98833090e-01]\n",
      "  ..., \n",
      "  [ -9.64851461e-02]\n",
      "  [  1.19270879e+00]\n",
      "  [ -1.57859288e+00]]]\n"
     ]
    }
   ],
   "source": [
    "weight_saver = ModelCheckpoint('set_a_weights.h5', monitor='val_loss', \n",
    "                               save_best_only=True, save_weights_only=True)\n",
    "\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.8**x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rohit/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (3,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-79bbc36fc466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight_saver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannealer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                    verbose=2)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    142\u001b[0m                                      str(validation_data))\n\u001b[1;32m    143\u001b[0m                 val_x, val_y, val_sample_weights = model._standardize_user_data(\n\u001b[0;32m--> 144\u001b[0;31m                     val_x, val_y, val_sample_weight)\n\u001b[0m\u001b[1;32m    145\u001b[0m                 \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 if model.uses_learning_phase and not isinstance(K.learning_phase(),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (3,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(batch_generator(x_train, y_train, 8),\n",
    "                   epochs=30, steps_per_epoch=1000,\n",
    "                   validation_data=(x_test, y_test),\n",
    "                   callbacks=[weight_saver, annealer],\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 13 layers into a model with 9 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-b61a90fae4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'set_a_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1166\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 13 layers into a model with 9 layers."
     ]
    }
   ],
   "source": [
    "model.load_weights('set_a_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "for i in range(3):\n",
    "    plt.plot(y_hat[:,i], c='r')\n",
    "    plt.plot(y_test[:,i], c='b')\n",
    "    plt.show()\n",
    "    print(CLASSES[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "for i in range(len(y_true)):\n",
    "    if y_pred[i] != y_true[i]:\n",
    "        print(\"File: {}, Pred: {}, True: {}\".format(\n",
    "            test_filenames[i],\n",
    "            CLASSES[y_pred[i]], CLASSES[y_true[i]]))\n",
    "        plt.plot(x_test[i])\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
